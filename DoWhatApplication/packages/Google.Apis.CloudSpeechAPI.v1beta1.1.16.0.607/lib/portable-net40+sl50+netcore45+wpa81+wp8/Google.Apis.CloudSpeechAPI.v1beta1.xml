<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Google.Apis.CloudSpeechAPI.v1beta1</name>
    </assembly>
    <members>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService">
            <summary>The CloudSpeechAPI Service.</summary>
        </member>
        <member name="F:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.Version">
            <summary>The API version.</summary>
        </member>
        <member name="F:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.DiscoveryVersionUsed">
            <summary>The discovery version used to generate this service.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.#ctor">
            <summary>Constructs a new service.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.#ctor(Google.Apis.Services.BaseClientService.Initializer)">
            <summary>Constructs a new service.</summary>
            <param name="initializer">The service initializer.</param>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.Features">
            <summary>Gets the service supported features.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.Name">
            <summary>Gets the service name.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.BaseUri">
            <summary>Gets the service base URI.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.BasePath">
            <summary>Gets the service base path.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.Scope">
            <summary>Available OAuth 2.0 scopes for use with the Google Cloud Speech API.</summary>
        </member>
        <member name="F:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.Scope.CloudPlatform">
            <summary>View and manage your data across Google Cloud Platform services</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.Operations">
            <summary>Gets the Operations resource.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIService.Speech">
            <summary>Gets the Speech resource.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1">
            <summary>A base abstract class for CloudSpeechAPI requests.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.#ctor(Google.Apis.Services.IClientService)">
            <summary>Constructs a new CloudSpeechAPIBaseServiceRequest instance.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.Xgafv">
            <summary>V1 error format.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.XgafvEnum">
            <summary>V1 error format.</summary>
        </member>
        <member name="F:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.XgafvEnum.Value1">
            <summary>v1 error format</summary>
        </member>
        <member name="F:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.XgafvEnum.Value2">
            <summary>v2 error format</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.AccessToken">
            <summary>OAuth access token.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.Alt">
            <summary>Data format for response.</summary>
            [default: json]
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.AltEnum">
            <summary>Data format for response.</summary>
        </member>
        <member name="F:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.AltEnum.Json">
            <summary>Responses with Content-Type of application/json</summary>
        </member>
        <member name="F:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.AltEnum.Media">
            <summary>Media download with context-dependent Content-Type</summary>
        </member>
        <member name="F:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.AltEnum.Proto">
            <summary>Responses with Content-Type of application/x-protobuf</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.BearerToken">
            <summary>OAuth bearer token.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.Callback">
            <summary>JSONP</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.Fields">
            <summary>Selector specifying which fields to include in a partial response.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.Key">
            <summary>API key. Your API key identifies your project and provides you with API access, quota, and reports.
            Required unless you provide an OAuth 2.0 token.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.OauthToken">
            <summary>OAuth 2.0 token for the current user.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.Pp">
            <summary>Pretty-print response.</summary>
            [default: true]
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.PrettyPrint">
            <summary>Returns response with indentations and line breaks.</summary>
            [default: true]
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.QuotaUser">
            <summary>Available to use for quota purposes for server-side applications. Can be any arbitrary string
            assigned to a user, but should not exceed 40 characters.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.UploadType">
            <summary>Legacy upload protocol for media (e.g. "media", "multipart").</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.UploadProtocol">
            <summary>Upload protocol for media (e.g. "raw", "multipart").</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.CloudSpeechAPIBaseServiceRequest`1.InitParameters">
            <summary>Initializes CloudSpeechAPI parameter list.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource">
            <summary>The "operations" collection of methods.</summary>
        </member>
        <member name="F:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.service">
            <summary>The service which this resource belongs to.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.#ctor(Google.Apis.Services.IClientService)">
            <summary>Constructs a new resource.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.Cancel(Google.Apis.CloudSpeechAPI.v1beta1.Data.CancelOperationRequest,System.String)">
            <summary>Starts asynchronous cancellation on a long-running operation.  The server makes a best effort to
            cancel the operation, but success is not guaranteed.  If the server doesn't support this method, it returns
            `google.rpc.Code.UNIMPLEMENTED`.  Clients can use Operations.GetOperation or other methods to check whether
            the cancellation succeeded or whether the operation completed despite cancellation.</summary>
            <param name="body">The body of the request.</param>
            <param name="name">The name of the operation resource to be cancelled.</param>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.CancelRequest">
            <summary>Starts asynchronous cancellation on a long-running operation.  The server makes a best effort to
            cancel the operation, but success is not guaranteed.  If the server doesn't support this method, it returns
            `google.rpc.Code.UNIMPLEMENTED`.  Clients can use Operations.GetOperation or other methods to check whether
            the cancellation succeeded or whether the operation completed despite cancellation.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.CancelRequest.#ctor(Google.Apis.Services.IClientService,Google.Apis.CloudSpeechAPI.v1beta1.Data.CancelOperationRequest,System.String)">
            <summary>Constructs a new Cancel request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.CancelRequest.Name">
            <summary>The name of the operation resource to be cancelled.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.CancelRequest.Body">
            <summary>Gets or sets the body of this request.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.CancelRequest.GetBody">
            <summary>Returns the body of the request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.CancelRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.CancelRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.CancelRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.CancelRequest.InitParameters">
            <summary>Initializes Cancel parameter list.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.Delete(System.String)">
            <summary>Deletes a long-running operation. This method indicates that the client is no longer interested in
            the operation result. It does not cancel the operation. If the server doesn't support this method, it
            returns `google.rpc.Code.UNIMPLEMENTED`.</summary>
            <param name="name">The name of the operation resource to be deleted.</param>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.DeleteRequest">
            <summary>Deletes a long-running operation. This method indicates that the client is no longer interested in
            the operation result. It does not cancel the operation. If the server doesn't support this method, it
            returns `google.rpc.Code.UNIMPLEMENTED`.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.DeleteRequest.#ctor(Google.Apis.Services.IClientService,System.String)">
            <summary>Constructs a new Delete request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.DeleteRequest.Name">
            <summary>The name of the operation resource to be deleted.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.DeleteRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.DeleteRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.DeleteRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.DeleteRequest.InitParameters">
            <summary>Initializes Delete parameter list.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.Get(System.String)">
            <summary>Gets the latest state of a long-running operation.  Clients can use this method to poll the
            operation result at intervals as recommended by the API service.</summary>
            <param name="name">The name of the operation resource.</param>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.GetRequest">
            <summary>Gets the latest state of a long-running operation.  Clients can use this method to poll the
            operation result at intervals as recommended by the API service.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.GetRequest.#ctor(Google.Apis.Services.IClientService,System.String)">
            <summary>Constructs a new Get request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.GetRequest.Name">
            <summary>The name of the operation resource.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.GetRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.GetRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.GetRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.GetRequest.InitParameters">
            <summary>Initializes Get parameter list.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.List">
             <summary>Lists operations that match the specified filter in the request. If the server doesn't support this
             method, it returns `UNIMPLEMENTED`.
            
             NOTE: the `name` binding below allows API services to override the binding to use different resource name
             schemes, such as `users/operations`.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.ListRequest">
             <summary>Lists operations that match the specified filter in the request. If the server doesn't support this
             method, it returns `UNIMPLEMENTED`.
            
             NOTE: the `name` binding below allows API services to override the binding to use different resource name
             schemes, such as `users/operations`.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.ListRequest.#ctor(Google.Apis.Services.IClientService)">
            <summary>Constructs a new List request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.ListRequest.PageSize">
            <summary>The standard list page size.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.ListRequest.Filter">
            <summary>The standard list filter.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.ListRequest.Name">
            <summary>The name of the operation collection.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.ListRequest.PageToken">
            <summary>The standard list page token.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.ListRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.ListRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.ListRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.OperationsResource.ListRequest.InitParameters">
            <summary>Initializes List parameter list.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource">
            <summary>The "speech" collection of methods.</summary>
        </member>
        <member name="F:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.service">
            <summary>The service which this resource belongs to.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.#ctor(Google.Apis.Services.IClientService)">
            <summary>Constructs a new resource.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.Asyncrecognize(Google.Apis.CloudSpeechAPI.v1beta1.Data.AsyncRecognizeRequest)">
            <summary>Perform asynchronous speech-recognition: receive results via the google.longrunning.Operations
            interface. Returns either an `Operation.error` or an `Operation.response` which contains an
            `AsyncRecognizeResponse` message.</summary>
            <param name="body">The body of the request.</param>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.AsyncrecognizeRequest">
            <summary>Perform asynchronous speech-recognition: receive results via the google.longrunning.Operations
            interface. Returns either an `Operation.error` or an `Operation.response` which contains an
            `AsyncRecognizeResponse` message.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.AsyncrecognizeRequest.#ctor(Google.Apis.Services.IClientService,Google.Apis.CloudSpeechAPI.v1beta1.Data.AsyncRecognizeRequest)">
            <summary>Constructs a new Asyncrecognize request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.AsyncrecognizeRequest.Body">
            <summary>Gets or sets the body of this request.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.AsyncrecognizeRequest.GetBody">
            <summary>Returns the body of the request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.AsyncrecognizeRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.AsyncrecognizeRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.AsyncrecognizeRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.AsyncrecognizeRequest.InitParameters">
            <summary>Initializes Asyncrecognize parameter list.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.Syncrecognize(Google.Apis.CloudSpeechAPI.v1beta1.Data.SyncRecognizeRequest)">
            <summary>Perform synchronous speech-recognition: receive results after all audio has been sent and
            processed.</summary>
            <param name="body">The body of the request.</param>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.SyncrecognizeRequest">
            <summary>Perform synchronous speech-recognition: receive results after all audio has been sent and
            processed.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.SyncrecognizeRequest.#ctor(Google.Apis.Services.IClientService,Google.Apis.CloudSpeechAPI.v1beta1.Data.SyncRecognizeRequest)">
            <summary>Constructs a new Syncrecognize request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.SyncrecognizeRequest.Body">
            <summary>Gets or sets the body of this request.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.SyncrecognizeRequest.GetBody">
            <summary>Returns the body of the request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.SyncrecognizeRequest.MethodName">
            <summary>Gets the method name.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.SyncrecognizeRequest.HttpMethod">
            <summary>Gets the HTTP method.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.SyncrecognizeRequest.RestPath">
            <summary>Gets the REST path.</summary>
        </member>
        <member name="M:Google.Apis.CloudSpeechAPI.v1beta1.SpeechResource.SyncrecognizeRequest.InitParameters">
            <summary>Initializes Syncrecognize parameter list.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.AsyncRecognizeRequest">
            <summary>`AsyncRecognizeRequest` is the top-level message sent by the client for the `AsyncRecognize`
            method.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.AsyncRecognizeRequest.Audio">
            <summary>[Required] The audio data to be recognized.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.AsyncRecognizeRequest.Config">
            <summary>[Required] The `config` message provides information to the recognizer that specifies how to
            process the request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.AsyncRecognizeRequest.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.CancelOperationRequest">
            <summary>The request message for Operations.CancelOperation.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.CancelOperationRequest.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.Empty">
             <summary>A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A
             typical example is to use it as the request or the response type of an API method. For instance:
            
             service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); }
            
             The JSON representation for `Empty` is empty JSON object `{}`.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Empty.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.ListOperationsResponse">
            <summary>The response message for Operations.ListOperations.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.ListOperationsResponse.NextPageToken">
            <summary>The standard List next-page token.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.ListOperationsResponse.Operations">
            <summary>A list of operations that matches the specified filter in the request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.ListOperationsResponse.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.Operation">
            <summary>This resource represents a long-running operation that is the result of a network API call.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Operation.Done">
            <summary>If the value is `false`, it means the operation is still in progress. If true, the operation is
            completed, and either `error` or `response` is available.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Operation.Error">
            <summary>The error result of the operation in case of failure.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Operation.Metadata">
            <summary>Service-specific metadata associated with the operation.  It typically contains progress
            information and common metadata such as create time. Some services might not provide such metadata.  Any
            method that returns a long-running operation should document the metadata type, if any.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Operation.Name">
            <summary>The server-assigned name, which is only unique within the same service that originally returns it.
            If you use the default HTTP mapping, the `name` should have the format of
            `operations/some/unique/name`.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Operation.Response">
            <summary>The normal response of the operation in case of success.  If the original method returns no data on
            success, such as `Delete`, the response is `google.protobuf.Empty`.  If the original method is standard
            `Get`/`Create`/`Update`, the response should be the resource.  For other methods, the response should have
            the type `XxxResponse`, where `Xxx` is the original method name.  For example, if the original method name
            is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Operation.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionAudio">
            <summary>Contains audio data in the encoding specified in the `RecognitionConfig`. Either `content` or `uri`
            must be supplied. Supplying both or neither returns google.rpc.Code.INVALID_ARGUMENT. See [audio
            limits](https://cloud.google.com/speech/limits#content).</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionAudio.Content">
            <summary>The audio data bytes encoded as specified in `RecognitionConfig`. Note: as with all bytes fields,
            protobuffers use a pure binary representation, whereas JSON representations use base64.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionAudio.Uri">
            <summary>URI that points to a file that contains audio data bytes as specified in `RecognitionConfig`.
            Currently, only Google Cloud Storage URIs are supported, which must be specified in the following format:
            `gs://bucket_name/object_name` (other URI formats return google.rpc.Code.INVALID_ARGUMENT). For more
            information, see [Request URIs](https://cloud.google.com/storage/docs/reference-uris).</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionAudio.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionConfig">
            <summary>The `RecognitionConfig` message provides information to the recognizer that specifies how to process
            the request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionConfig.Encoding">
            <summary>[Required] Encoding of audio data sent in all `RecognitionAudio` messages.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionConfig.LanguageCode">
            <summary>[Optional] The language of the supplied audio as a BCP-47 language tag. Example: "en-GB"
            https://www.rfc-editor.org/rfc/bcp/bcp47.txt If omitted, defaults to "en-US". See [Language
            Support](https://cloud.google.com/speech/docs/best-practices#language_support) for a list of the currently
            supported language codes.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionConfig.MaxAlternatives">
            <summary>[Optional] Maximum number of recognition hypotheses to be returned. Specifically, the maximum
            number of `SpeechRecognitionAlternative` messages within each `SpeechRecognitionResult`. The server may
            return fewer than `max_alternatives`. Valid values are `0`-`30`. A value of `0` or `1` will return a maximum
            of `1`. If omitted, defaults to `1`.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionConfig.ProfanityFilter">
            <summary>[Optional] If set to `true`, the server will attempt to filter out profanities, replacing all but
            the initial character in each filtered word with asterisks, e.g. "f***". If set to `false` or omitted,
            profanities won't be filtered out.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionConfig.SampleRate">
            <summary>[Required] Sample rate in Hertz of the audio data sent in all `RecognitionAudio` messages. Valid
            values are: 8000-48000. 16000 is optimal. For best results, set the sampling rate of the audio source to
            16000 Hz. If that's not possible, use the native sample rate of the audio source (instead of re-
            sampling).</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionConfig.SpeechContext">
            <summary>[Optional] A means to provide context to assist the speech recognition.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.RecognitionConfig.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.SpeechContext">
            <summary>Provides "hints" to the speech recognizer to favor specific words and phrases in the results.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SpeechContext.Phrases">
            <summary>[Optional] A list of strings containing words and phrases "hints" so that the speech recognition is
            more likely to recognize them. This can be used to improve the accuracy for specific words and phrases, for
            example, if specific commands are typically spoken by the user. This can also be used to add additional
            words to the vocabulary of the recognizer. See [usage
            limits](https://cloud.google.com/speech/limits#content).</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SpeechContext.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.SpeechRecognitionAlternative">
            <summary>Alternative hypotheses (a.k.a. n-best list).</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SpeechRecognitionAlternative.Confidence">
            <summary>[Output-only] The confidence estimate between 0.0 and 1.0. A higher number means the system is more
            confident that the recognition is correct. This field is typically provided only for the top hypothesis, and
            only for `is_final=true` results. The default of 0.0 is a sentinel value indicating confidence was not
            set.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SpeechRecognitionAlternative.Transcript">
            <summary>[Output-only] Transcript text representing the words that the user spoke.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SpeechRecognitionAlternative.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.SpeechRecognitionResult">
            <summary>A speech recognition result corresponding to a portion of the audio.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SpeechRecognitionResult.Alternatives">
            <summary>[Output-only] May contain one or more recognition hypotheses (up to the maximum specified in
            `max_alternatives`).</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SpeechRecognitionResult.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.Status">
             <summary>The `Status` type defines a logical error model that is suitable for different programming
             environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). The error model
             is designed to be:
            
             - Simple to use and understand for most users - Flexible enough to meet unexpected needs
            
             # Overview
            
             The `Status` message contains three pieces of data: error code, error message, and error details. The error code
             should be an enum value of google.rpc.Code, but it may accept additional error codes if needed.  The error
             message should be a developer-facing English message that helps developers *understand* and *resolve* the error.
             If a localized user-facing error message is needed, put the localized message in the error details or localize
             it in the client. The optional error details may contain arbitrary information about the error. There is a
             predefined set of error detail types in the package `google.rpc` which can be used for common error conditions.
            
             # Language mapping
            
             The `Status` message is the logical representation of the error model, but it is not necessarily the actual wire
             format. When the `Status` message is exposed in different client libraries and different wire protocols, it can
             be mapped differently. For example, it will likely be mapped to some exceptions in Java, but more likely mapped
             to some error codes in C.
            
             # Other uses
            
             The error model and the `Status` message can be used in a variety of environments, either with or without APIs,
             to provide a consistent developer experience across different environments.
            
             Example uses of this error model include:
            
             - Partial errors. If a service needs to return partial errors to the client, it may embed the `Status` in the
             normal response to indicate the partial errors.
            
             - Workflow errors. A typical workflow has multiple steps. Each step may have a `Status` message for error
             reporting purpose.
            
             - Batch operations. If a client uses batch request and batch response, the `Status` message should be used
             directly inside batch response, one for each error sub-response.
            
             - Asynchronous operations. If an API call embeds asynchronous operation results in its response, the status of
             those operations should be represented directly using the `Status` message.
            
             - Logging. If some API errors are stored in logs, the message `Status` could be used directly after any
             stripping needed for security/privacy reasons.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Status.Code">
            <summary>The status code, which should be an enum value of google.rpc.Code.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Status.Details">
            <summary>A list of messages that carry the error details.  There will be a common set of message types for
            APIs to use.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Status.Message">
            <summary>A developer-facing error message, which should be in English. Any user-facing error message should
            be localized and sent in the google.rpc.Status.details field, or localized by the client.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.Status.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.SyncRecognizeRequest">
            <summary>`SyncRecognizeRequest` is the top-level message sent by the client for the `SyncRecognize`
            method.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SyncRecognizeRequest.Audio">
            <summary>[Required] The audio data to be recognized.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SyncRecognizeRequest.Config">
            <summary>[Required] The `config` message provides information to the recognizer that specifies how to
            process the request.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SyncRecognizeRequest.ETag">
            <summary>The ETag of the item.</summary>
        </member>
        <member name="T:Google.Apis.CloudSpeechAPI.v1beta1.Data.SyncRecognizeResponse">
            <summary>`SyncRecognizeResponse` is the only message returned to the client by `SyncRecognize`. It contains the
            result as zero or more sequential `SpeechRecognitionResult` messages.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SyncRecognizeResponse.Results">
            <summary>[Output-only] Sequential list of transcription results corresponding to sequential portions of
            audio.</summary>
        </member>
        <member name="P:Google.Apis.CloudSpeechAPI.v1beta1.Data.SyncRecognizeResponse.ETag">
            <summary>The ETag of the item.</summary>
        </member>
    </members>
</doc>
